{
 "cells": [
  {
   "cell_type": "raw",
   "id": "moved-damages",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cosmetic-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid, cross_validate\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import decomposition\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import itertools\n",
    "import random\n",
    "import warnings\n",
    "import string\n",
    "from shutil import copyfile\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-evanescence",
   "metadata": {},
   "source": [
    "### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "centered-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_shuffle_seed = 4\n",
    "global_debug=True\n",
    "global_override=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-smart",
   "metadata": {},
   "source": [
    "### Load tagtog Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "concrete-vulnerability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 1597 True: 858 False: 739\n"
     ]
    }
   ],
   "source": [
    "result, clf_result = {}, {}\n",
    "df_data = load_data_tagtog(['../tagtog/output'])\n",
    "df_data = df_data[df_data['is_flood'].notna()]\n",
    "data_true = query_dataframe(df_data, {'is_flood':True})\n",
    "data_false = query_dataframe(df_data, {'is_flood':False})\n",
    "print('Total:',len(df_data),'True:',len(data_true), 'False:',len(data_false))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-polymer",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ethical-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's consider with and without stop words\n",
    "\n",
    "custom_stop_words = set(['date', 'published'])\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "punctuations = set(string.punctuation)\n",
    "all_stop_words = stop_words.union(punctuations, custom_stop_words)\n",
    "def preprocess(x):\n",
    "    x = re.sub('[^a-z\\s]', ' ', x.lower())\n",
    "    x = [w for w in x.split() if w not in all_stop_words and len(w)>3]\n",
    "    return ' '.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "opening-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['org_text'] = df_data['text']\n",
    "df_data['text'] = df_data['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-retail",
   "metadata": {},
   "source": [
    "## Size and Ratio Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "north-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 40\n",
    "#df_data[\"text\"][n], df_data[\"org_text\"][n]\n",
    "floodArticles = df_data[df_data[\"is_flood\"] == True]\n",
    "nonfloodArticles = df_data[df_data[\"is_flood\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "explicit-sense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newspaper splits\n",
      "All [('daily_star', 324), ('dhaka_tribune', 443), (None, 973), ('ny_times', 206)]\n",
      "Flood [('daily_star', 153), ('dhaka_tribune', 108), (None, 301), ('ny_times', 40)]\n",
      "Not Flood [('daily_star', 171), ('dhaka_tribune', 335), (None, 672), ('ny_times', 166)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Newspaper splits\")\n",
    "def newspaperCounts(df_data):\n",
    "    return [(t, sum(df_data['newspaper'].notna()) if t==None else sum(df_data['newspaper']==t)) for t in set(df_data['newspaper'])]\n",
    "\n",
    "print(\"All\", newspaperCounts(df_data))\n",
    "print(\"Flood\", newspaperCounts(floodArticles))\n",
    "print(\"Not Flood\", newspaperCounts(nonfloodArticles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "saving-river",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average size of the text is 317.0 with deviation 257.0\n",
      "For unnassociated newspapers the average size of the text is 350.0 with deviation 296.0\n",
      "For daily_star newspapers the average size of the text is 355.0 with deviation 222.0\n",
      "For dhaka_tribune newspapers the average size of the text is 253.0 with deviation 173.0\n",
      "For ny_times newspapers the average size of the text is 549.0 with deviation 461.0\n",
      "For unnassociated flood newspapers the average size of the text is 300.0 with deviation 172.0\n",
      "For daily_star flood newspapers the average size of the text is 322.0 with deviation 172.0\n",
      "For dhaka_tribune flood newspapers the average size of the text is 274.0 with deviation 148.0\n",
      "For ny_times flood newspapers the average size of the text is 287.0 with deviation 215.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getWordCountStats(df):\n",
    "    counts = df.apply(lambda txt: len(txt.split(\" \")))\n",
    "    return counts, round(np.mean(counts)), round(np.std(counts))\n",
    "\n",
    "counts, mu, std = getWordCountStats(df_data[\"text\"])\n",
    "\n",
    "restrictions = [(\"unnassociated\", df_data['newspaper'].notna())] \n",
    "restrictions += [(t, df_data['newspaper']==t) for t in set(df_data['newspaper']) if t !=None]\n",
    "restrictions += [(name + \" flood\", filt & df_data[\"is_flood\"]==True) for name, filt in restrictions]\n",
    "\n",
    "print(\"The average size of the text is {} with deviation {}\".format(mu, std))\n",
    "\n",
    "for name, filt in restrictions:\n",
    "    _, mu, std = getWordCountStats(df_data[filt][\"text\"])\n",
    "    print(\"For {} newspapers the average size of the text is {} with deviation {}\".format(name, mu, std))\n",
    "\n",
    "plt.hist(counts, bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-remark",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "photographic-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_ratio(df_data, test_size=None, train_size=None, shuffle_seed=4, debug=False, \n",
    "                    save_folder=None, load_folder=None, override=False, file_prefix=''):\n",
    "    save_file, load_file=None, None\n",
    "    if save_folder: save_file = os.path.join(save_folder,file_prefix+'data.json')\n",
    "    if load_folder: load_file = os.path.join(load_folder,file_prefix+'data.json')\n",
    "    \n",
    "    if not override and load_file and os.path.isfile(load_file):\n",
    "        if debug: print('loaded',load_file)\n",
    "        js = json.load(open(load_file))\n",
    "        train_df = pd.DataFrame(js['train'])\n",
    "        test_df = pd.DataFrame(js['test'])\n",
    "        return {'train':train_df, 'test':test_df}\n",
    "    \n",
    "    train_df, test_df = train_test_split(df_data, test_size=test_size, train_size=train_size, random_state=shuffle_seed, stratify=df_data['is_flood'])\n",
    "    \n",
    "#     true_data = df_data.loc[df_data['is_flood']==True]\n",
    "#     false_data = df_data.loc[df_data['is_flood']==False]\n",
    "#     train_true, test_true = train_test_split(true_data, test_size=test_size, random_state=shuffle_seed)\n",
    "#     train_false, test_false = train_test_split(false_data, test_size=test_size, random_state=shuffle_seed)\n",
    "    \n",
    "#     train_df = pd.concat([train_true, train_false])\n",
    "#     train_df = train_df.sample(n=len(train_df), random_state=shuffle_seed).reset_index(drop=True)\n",
    "#     test_df = pd.concat([test_true, test_false])\n",
    "#     test_df = test_df.sample(n=len(test_df), random_state=shuffle_seed).reset_index(drop=True)\n",
    "    \n",
    "    if debug: print('Data Loaded')\n",
    "\n",
    "    if save_file:\n",
    "        train_json = train_df.to_json(orient='records')\n",
    "        test_json = test_df.to_json(orient='records')\n",
    "        json.dump({'train':json.loads(train_json), 'test':json.loads(test_json)}, open(save_file,'w'), indent=2)\n",
    "    return {'train':train_df, 'test':test_df}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "legislative-signature",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "result, clf_result = {}, {}\n",
    "save_data_folder = 'data_splits/'\n",
    "load_data_folder = 'data_splits/'\n",
    "test_size = 0.2\n",
    "if not os.path.isdir(save_data_folder): os.mkdir(save_data_folder)\n",
    "debug=global_debug or False\n",
    "override=global_override or False\n",
    "data_split = make_data_ratio(df_data, test_size=test_size, save_folder=save_data_folder, load_folder=load_data_folder, \n",
    "                               debug=debug, shuffle_seed=global_shuffle_seed, override=override)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "offshore-cleaner",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1277 \t\tTest: 320\n",
      "Train is_flood: 686 \tTrain not is_flood: 591\n",
      "Test is_flood: 172 \tTest not is_flood: 148\n"
     ]
    }
   ],
   "source": [
    "print('Train:',len(data_split['train']), '\\t\\tTest:',len(data_split['test']))\n",
    "print('Train is_flood:',len(data_split['train'].loc[data_split['train']['is_flood']==True]), \\\n",
    "'\\tTrain not is_flood:',len(data_split['train'].loc[data_split['train']['is_flood']==False]))\n",
    "print('Test is_flood:',len(data_split['test'].loc[data_split['test']['is_flood']==True]), \\\n",
    "'\\tTest not is_flood:',len(data_split['test'].loc[data_split['test']['is_flood']==False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-validity",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "administrative-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(vect_fit, ratio):\n",
    "    train, test = ratio.get('train',None), ratio.get('test',None)\n",
    "    if train is None or test is None: raise Exception('Train or Test data not found')\n",
    "    all_X = list(train['text'])\n",
    "    \n",
    "    vect = vect_fit.fit(all_X)\n",
    "    trainX, testX = vect.transform(list(train['text'])), vect.transform(list(test['text']))\n",
    "    trainY, testY = [1 if t else 0 for t in train['is_flood']], [1 if t else 0 for t in test['is_flood']]\n",
    "    return trainX, testX, trainY, testY, vect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "controversial-bankruptcy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1277, 28650)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX, testX, trainY, testY, vectorizer = make_data(TfidfVectorizer(), data_split)\n",
    "trainX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-algorithm",
   "metadata": {},
   "source": [
    "### Quick Naive Bayes Model with TfIdf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "disabled-notification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words frequencies predicting flood articles: \n",
      "flowing, danger, flooded, inundated, marooned, upazilas, erosion, floods, affected\n",
      "\n",
      "Words frequencies predicting non-flood articles: \n",
      "coronavirus, bangabandhu, york, world, economic, growth, countries, election, trade, american\n",
      "\n",
      "Accuracy is 0.884375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes_clf = MultinomialNB().fit(trainX, trainY)\n",
    "\n",
    "feature_names = np.array(vectorizer.get_feature_names())\n",
    "odds = np.argsort(naive_bayes_clf.feature_log_prob_[0, :]/naive_bayes_clf.feature_log_prob_[1, :])\n",
    "\n",
    "print(\"Words frequencies predicting flood articles: \")\n",
    "print(\", \".join(feature_names[odds[:-10:-1]]))\n",
    "\n",
    "print(\"\\nWords frequencies predicting non-flood articles: \")\n",
    "print(\", \".join(feature_names[odds[:10]]))\n",
    "\n",
    "print(\"\\nAccuracy is {}\".format(accuracy_score(testY, naive_bayes_clf.predict(testX))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-enhancement",
   "metadata": {},
   "source": [
    "### Decision Tree with TfIdf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "rough-hudson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "satellite-resort",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88125"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(testY, clf.predict(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "pressing-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier(clf, trainX, testX, trainY, testY):\n",
    "    clf_fit = clf.fit(trainX, trainY)\n",
    "    clf_pred = clf_fit.predict(testX)\n",
    "    clf_acc = accuracy_score(testY, clf_pred)\n",
    "    return clf_fit, clf_pred, clf_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "educational-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_method(main_d, name):\n",
    "    if name not in main_d: raise Exception('Cannot find classifier/feature_extractor name in parameter dictionary')\n",
    "    d = main_d[name]\n",
    "    method = d.get('method',None)\n",
    "    base_method = d.get('base_method',None)\n",
    "    if method and base_method: raise Exception('Cannot have method and base method both.')\n",
    "    if not method and not base_method: raise Exception('Unable to parse the method from classifier/feature_extractor')\n",
    "    params = d.get('params',None)\n",
    "    if method:\n",
    "        if params: return method, params\n",
    "        else: return method, None\n",
    "    if base_method:\n",
    "        prev_method, prev_params = get_method(main_d, base_method)\n",
    "        if params:\n",
    "            for k,v in params.items(): prev_params[k] = v\n",
    "        return prev_method, prev_params\n",
    "\n",
    "def make_method(main_d, name, override_params={}):\n",
    "    method, params = get_method(main_d, name)[:]\n",
    "    if override_params:\n",
    "        for k,v in override_params.items(): params[k] = v\n",
    "    if params: return method(**params)\n",
    "    else: return method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "rising-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid(grid, data, feature_extract, classifiers, clf_result, result, \n",
    "             debug=False, override=False, save_folder=None, load_folder=None, file_prefix=''):\n",
    "    save_clf_result = {}\n",
    "    vectCache, classifierCache = {}, {}\n",
    "    if load_folder:\n",
    "        res_file = os.path.join(load_folder,file_prefix+'clf_result.json')\n",
    "        clf_res_file = os.path.join(load_folder,file_prefix+'result.json')\n",
    "        if os.path.isfile(res_file): clf_result=json.load(open(res_file))\n",
    "        if os.path.isfile(clf_res_file): result=json.load(open(clf_res_file))\n",
    "        if os.path.isfile(res_file) and os.path.isfile(clf_res_file) and debug: print('loaded result')\n",
    "    \n",
    "    if override:\n",
    "        clf_result, result = {}, {}\n",
    "        if debug: print('OVERRIDE')\n",
    "    for g in list(grid):\n",
    "        try:\n",
    "            feature_name = g.get('feature_extract',None)\n",
    "            clf_name = g.get('classifier', None)\n",
    "            if not feature_name or not clf_name:\n",
    "                raise Exception('Feature Extract and Classifier Name required')\n",
    "            result_key = feature_name + '-' + clf_name\n",
    "            if result.get(result_key): continue\n",
    "            if debug: print('Feature:', feature_name, '  Clasifier:',clf_name, '  Key:',result_key)\n",
    "            \n",
    "            if feature_name in vectCache:\n",
    "                (trainX, testX, trainY, testY, feature2) = vectCache[feature_name]\n",
    "            else:\n",
    "                feature = make_method(feature_extract, feature_name)\n",
    "                trainX, testX, trainY, testY, feature2 = make_data(feature, data)\n",
    "                vectCache[feature_name] = (trainX, testX, trainY, testY, feature2)\n",
    "\n",
    "            clf = make_method(classifiers, clf_name)\n",
    "            clf_fit, clf_pred, clf_acc = run_classifier(clf, trainX, testX, trainY, testY)\n",
    "            \n",
    "            result[result_key] = {\n",
    "                'feature_extract': feature_name,\n",
    "                'classifier': clf_name,\n",
    "                'accuracy': clf_acc\n",
    "            }\n",
    "            \n",
    "            clf_result[result_key] = {\n",
    "                'feature_extract': feature_name,\n",
    "                'classifier': clf_name,\n",
    "                'clf': clf_fit,\n",
    "                'feature': feature2,\n",
    "                'predict': clf_pred\n",
    "            }\n",
    "            \n",
    "            save_clf_result[result_key] = {\n",
    "                'feature_extract': feature_name,\n",
    "                'classifier': clf_name,\n",
    "                'predict': clf_pred.tolist()\n",
    "            }  \n",
    "        except Exception as e:\n",
    "            print('Error:',e)\n",
    "            continue\n",
    "    if save_folder:\n",
    "        json.dump(save_clf_result, open(os.path.join(load_folder,file_prefix+'clf_result.json'),'w'), indent=2)\n",
    "        json.dump(result, open(os.path.join(load_folder,file_prefix+'result.json'),'w'), indent=2)\n",
    "    return clf_result, result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "stretch-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_cross_validate(grid, data, feature_extract, classifiers, result, debug=False):\n",
    "    for g in list(grid):\n",
    "        feature_name = g.get('feature_extract',None)\n",
    "        clf_name = g.get('classifier', None)\n",
    "        if not feature_name or not clf_name:\n",
    "            raise Exception('Feature Extract and Classifier Name required')\n",
    "        result_key = feature_name + '-' + clf_name\n",
    "        if result.get(result_key): continue\n",
    "        if debug: print('Feature:', feature_name, '  Clasifier:',clf_name, '  Key:',result_key)\n",
    "\n",
    "        feature = make_method(feature_extract, 'TFIDF')\n",
    "        all_X = data['text']\n",
    "        all_Y = data['is_flood']\n",
    "        vect = feature.fit(all_X)\n",
    "        x, y = vect.transform(list(all_X)), [1 if t else 0 for t in all_Y]\n",
    "        clf = make_method(classifiers, clf_name)\n",
    "        cv = cross_validate(clf, x, y, cv=5,\n",
    "                      scoring=('accuracy', 'precision', 'recall', 'f1'))\n",
    "        result[result_key] = cv\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "compound-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_result(result, clf_result=None, data=None, accuracy_threshold=None, split_by='classifier'):\n",
    "    keys = list(result.keys())\n",
    "    temp_df = pd.DataFrame(list(result.values()))\n",
    "    if clf_result is not None and data is not None:\n",
    "        presicion, recall, f1, support = [], [], [], []\n",
    "        actual = [1 if f else 0 for f in list(data['test']['is_flood'])]\n",
    "        for method_name in keys:\n",
    "            predict = clf_result[method_name]['predict']\n",
    "            pre, rec, fsc, sup = precision_recall_fscore_support(actual, predict, average='binary')\n",
    "            presicion.append(pre)\n",
    "            recall.append(rec)\n",
    "            f1.append(fsc)\n",
    "            support.append(sup)\n",
    "        temp_df['f1'] = f1\n",
    "        temp_df['presicion'] = presicion\n",
    "        temp_df['recall'] = recall\n",
    "#     temp_df['keys'] = keys\n",
    "    splt_val = list(set(list(temp_df[split_by])))\n",
    "    for d in splt_val:\n",
    "        if accuracy_threshold:\n",
    "            new_df = temp_df.loc[temp_df[split_by]==d]\n",
    "            new_df = new_df.loc[new_df['accuracy']>accuracy_threshold] \\\n",
    "                            .drop(split_by, axis=1) \\\n",
    "                            .sort_values(by='accuracy',ascending=False) \\\n",
    "                            .reset_index(drop=True)\n",
    "        else:\n",
    "            new_df = temp_df.loc[temp_df[split_by]==d] \\\n",
    "                            .drop(split_by, axis=1) \\\n",
    "                            .sort_values(by='accuracy',ascending=False) \\\n",
    "                            .reset_index(drop=True)\n",
    "        print('{}: {}'.format(split_by,d))\n",
    "        print(new_df.to_markdown())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "sublime-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vocab(ratio):\n",
    "    train, test = ratio.get('train',None), ratio.get('test',None)\n",
    "    if train is None or test is None: raise Exception('Train or Test data not found')\n",
    "    all_X = list(train['text']) + list(test['text'])\n",
    "    \n",
    "    params= {\n",
    "            'tokenizer': word_tokenize,\n",
    "            'stop_words': 'english',\n",
    "        }\n",
    "    vect = CountVectorizer(**params)\n",
    "    vect = vect.fit(all_X)\n",
    "    return list(vect.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "civil-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "vocab = make_vocab(data_split)\n",
    "feature_extract = {\n",
    "    'CountVect': {\n",
    "        'classifier_type': 'Count Vectorizer',\n",
    "        'method': CountVectorizer,\n",
    "        'params': {\n",
    "            'tokenizer': word_tokenize,\n",
    "            'stop_words': 'english',\n",
    "            'vocabulary': vocab\n",
    "        }\n",
    "    },\n",
    "    'CountVect-2gram':{\n",
    "        'base_method': 'CountVect',\n",
    "        'params':{\n",
    "            'ngram_range':(1,2)\n",
    "        }\n",
    "    },\n",
    "    'CountVect-min_df-max_df':{\n",
    "        'base_method': 'CountVect',\n",
    "        'params':{\n",
    "            'min_df': 0.05,\n",
    "            'max_df': 0.95\n",
    "        }\n",
    "    },\n",
    "    'CountVect-2gram-min_df-max_df':{\n",
    "        'base_method': 'CountVect',\n",
    "        'params':{\n",
    "            'min_df': 0.05,\n",
    "            'max_df': 0.95,\n",
    "            'ngram_range':(1,2)\n",
    "        }\n",
    "    },\n",
    "    'TFIDF': {\n",
    "        'classifier_type': 'TFIDF',\n",
    "        'method': TfidfVectorizer,\n",
    "        'params': {\n",
    "            'tokenizer': word_tokenize,\n",
    "            'stop_words': 'english',\n",
    "            'vocabulary': vocab\n",
    "        }\n",
    "    },\n",
    "    'TFIDF-2gram':{\n",
    "        'base_method': 'TFIDF',\n",
    "        'params':{\n",
    "            'ngram_range':(1,2)\n",
    "        }\n",
    "    },\n",
    "    'TFIDF-min_df-max_df':{\n",
    "        'base_method': 'TFIDF',\n",
    "        'params':{\n",
    "            'min_df': 0.05,\n",
    "            'max_df': 0.95\n",
    "        }\n",
    "    },\n",
    "    'TFIDF-2gram-min_df-max_df':{\n",
    "        'base_method': 'TFIDF',\n",
    "        'params':{\n",
    "            'min_df': 0.05,\n",
    "            'max_df': 0.95,\n",
    "            'ngram_range':(1,2)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "classifiers = {\n",
    "    'RandomForest': {\n",
    "        'classifier_type':'Random Forest ',\n",
    "        'method': RandomForestClassifier,\n",
    "        'params':{\n",
    "            'class_weight':'balanced'\n",
    "        }\n",
    "    },\n",
    "    'LinearSVC': {\n",
    "        'classifier_type': 'Linear SVC',\n",
    "        'method': LinearSVC,\n",
    "        'params':{\n",
    "            'class_weight':'balanced'\n",
    "        }\n",
    "    },\n",
    "    'LogRegL1':{\n",
    "        'classifier_type': 'Logistic Regression L1',\n",
    "        'method': LogisticRegression,\n",
    "        'params':{\n",
    "            'penalty': 'l1',\n",
    "            'class_weight':'balanced',\n",
    "            'solver': 'liblinear',\n",
    "            'max_iter': 1000\n",
    "        }\n",
    "    },\n",
    "    'LogRegL2':{\n",
    "        'classifier_type': 'Logistic Regression L2',\n",
    "        'method': LogisticRegression,\n",
    "        'params':{\n",
    "            'penalty': 'l2',\n",
    "            'class_weight':'balanced',\n",
    "            'solver': 'liblinear',\n",
    "            'max_iter': 1000\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "grid_parameters = {\n",
    "    'feature_extract': list(feature_extract.keys()),\n",
    "    'classifier': list(classifiers.keys()),\n",
    "}\n",
    "\n",
    "grid = ParameterGrid(grid_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "thirty-break",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERRIDE\n",
      "Feature: CountVect   Clasifier: RandomForest   Key: CountVect-RandomForest\n",
      "Feature: CountVect-2gram   Clasifier: RandomForest   Key: CountVect-2gram-RandomForest\n",
      "Feature: CountVect-min_df-max_df   Clasifier: RandomForest   Key: CountVect-min_df-max_df-RandomForest\n",
      "Feature: CountVect-2gram-min_df-max_df   Clasifier: RandomForest   Key: CountVect-2gram-min_df-max_df-RandomForest\n",
      "Feature: TFIDF   Clasifier: RandomForest   Key: TFIDF-RandomForest\n",
      "Feature: TFIDF-2gram   Clasifier: RandomForest   Key: TFIDF-2gram-RandomForest\n",
      "Feature: TFIDF-min_df-max_df   Clasifier: RandomForest   Key: TFIDF-min_df-max_df-RandomForest\n",
      "Feature: TFIDF-2gram-min_df-max_df   Clasifier: RandomForest   Key: TFIDF-2gram-min_df-max_df-RandomForest\n",
      "Feature: CountVect   Clasifier: LinearSVC   Key: CountVect-LinearSVC\n",
      "Feature: CountVect-2gram   Clasifier: LinearSVC   Key: CountVect-2gram-LinearSVC\n",
      "Feature: CountVect-min_df-max_df   Clasifier: LinearSVC   Key: CountVect-min_df-max_df-LinearSVC\n",
      "Feature: CountVect-2gram-min_df-max_df   Clasifier: LinearSVC   Key: CountVect-2gram-min_df-max_df-LinearSVC\n",
      "Feature: TFIDF   Clasifier: LinearSVC   Key: TFIDF-LinearSVC\n",
      "Feature: TFIDF-2gram   Clasifier: LinearSVC   Key: TFIDF-2gram-LinearSVC\n",
      "Feature: TFIDF-min_df-max_df   Clasifier: LinearSVC   Key: TFIDF-min_df-max_df-LinearSVC\n",
      "Feature: TFIDF-2gram-min_df-max_df   Clasifier: LinearSVC   Key: TFIDF-2gram-min_df-max_df-LinearSVC\n",
      "Feature: CountVect   Clasifier: LogRegL1   Key: CountVect-LogRegL1\n",
      "Feature: CountVect-2gram   Clasifier: LogRegL1   Key: CountVect-2gram-LogRegL1\n",
      "Feature: CountVect-min_df-max_df   Clasifier: LogRegL1   Key: CountVect-min_df-max_df-LogRegL1\n",
      "Feature: CountVect-2gram-min_df-max_df   Clasifier: LogRegL1   Key: CountVect-2gram-min_df-max_df-LogRegL1\n",
      "Feature: TFIDF   Clasifier: LogRegL1   Key: TFIDF-LogRegL1\n",
      "Feature: TFIDF-2gram   Clasifier: LogRegL1   Key: TFIDF-2gram-LogRegL1\n",
      "Feature: TFIDF-min_df-max_df   Clasifier: LogRegL1   Key: TFIDF-min_df-max_df-LogRegL1\n",
      "Feature: TFIDF-2gram-min_df-max_df   Clasifier: LogRegL1   Key: TFIDF-2gram-min_df-max_df-LogRegL1\n",
      "Feature: CountVect   Clasifier: LogRegL2   Key: CountVect-LogRegL2\n",
      "Feature: CountVect-2gram   Clasifier: LogRegL2   Key: CountVect-2gram-LogRegL2\n",
      "Feature: CountVect-min_df-max_df   Clasifier: LogRegL2   Key: CountVect-min_df-max_df-LogRegL2\n",
      "Feature: CountVect-2gram-min_df-max_df   Clasifier: LogRegL2   Key: CountVect-2gram-min_df-max_df-LogRegL2\n",
      "Feature: TFIDF   Clasifier: LogRegL2   Key: TFIDF-LogRegL2\n",
      "Feature: TFIDF-2gram   Clasifier: LogRegL2   Key: TFIDF-2gram-LogRegL2\n",
      "Feature: TFIDF-min_df-max_df   Clasifier: LogRegL2   Key: TFIDF-min_df-max_df-LogRegL2\n",
      "Feature: TFIDF-2gram-min_df-max_df   Clasifier: LogRegL2   Key: TFIDF-2gram-min_df-max_df-LogRegL2\n"
     ]
    }
   ],
   "source": [
    "override=global_override or False\n",
    "debug=global_debug or False\n",
    "save_results_folder = 'results/'\n",
    "load_results_folder = 'results/'\n",
    "if not os.path.isdir(save_results_folder): os.mkdir(save_results_folder)\n",
    "clf_result, result = run_grid(grid, data_split, feature_extract, classifiers, clf_result, result, \n",
    "                              debug=debug, override=override, save_folder=save_results_folder, \n",
    "                             load_folder=load_results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-template",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
