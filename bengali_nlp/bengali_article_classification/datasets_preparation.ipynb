{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "retained-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-conviction",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Loading Annotated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "varied-empire",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from bengali_data_management.tagtogLoader import load_from_annotations_folder\n",
    "df1 = load_from_annotations_folder(\"../../tagtog/datasets/annotations_large_mixed_batch/\", csv_folder=\"../bengali_data_management/samples/formated\")\n",
    "df2 = load_from_annotations_folder(\"../../tagtog/datasets/annotations_exact_match/\", csv_folder=\"../bengali_data_management/samples/formated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aware-complex",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>content</th>\n",
       "      <th>is_flood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8639</td>\n",
       "      <td>কুষ্টিয়ায় পানিবন্দী ৩৫ ...</td>\n",
       "      <td>৩ দিন আগে</td>\n",
       "      <td>কুষ্টিয়ায় পানিবন্দী ৩৫ গ্রামের মানুষ</td>\n",
       "      <td>চরাঞ্চলে সাধারণত আষাঢ়–ভাদ্র মাসের মাঝামাঝি পর্...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27195</td>\n",
       "      <td>পানিবন্দি কয়েক লাখ মানুষ</td>\n",
       "      <td>১৩ জুলাই, ২০২০</td>\n",
       "      <td>পানিবন্দি কয়েক লাখ মানুষ</td>\n",
       "      <td>সুনামগঞ্জ প্রতিনিধি\\nশেষের পাতা  ১৩ জুলাই ২০২০...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>292</td>\n",
       "      <td>মৌলভীবাজারে পাহাড়ি ঢলে ... - Prothom Alo</td>\n",
       "      <td>৫ জুন, ২০১৭</td>\n",
       "      <td>মৌলভীবাজারে পাহাড়ি ঢলে লক্ষাধিক মানুষ পানিবন্দী</td>\n",
       "      <td>&gt;\\nজনপ্রতিনিধিরা ব্যক্তিগত উদ্যোগে কিছু ত্রাণ ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28981</td>\n",
       "      <td>দুর্যোগ সহনশীল নগর গঠনে নারীর ...</td>\n",
       "      <td>২৫ ফেব, ২০১৮</td>\n",
       "      <td>দুর্যোগ সহনশীল নগর গঠনে নারীর ভূমিকা</td>\n",
       "      <td>১৮ ফেব্রুয়ারি ২০১৮, ডেইলি স্টার ওকেয়ার বাংলাদে...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4913</td>\n",
       "      <td>গরমের তেজে নিস্তেজ জীবন | 942173 ...</td>\n",
       "      <td>৫ আগস্ট, ২০২০</td>\n",
       "      <td>গরমের তেজে নিস্তেজ জীবন</td>\n",
       "      <td>কখনো ঠা ঠা রোদ আবার কখনো মধ্য শ্রাবণের অঝোরধার...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>7198</td>\n",
       "      <td>দুর্যোগ মোকাবিলায় হাসপাতালের ...</td>\n",
       "      <td>২৬ মার্চ, ২০১৯</td>\n",
       "      <td>দুর্যোগ মোকাবিলায় হাসপাতালের প্রস্তুতি</td>\n",
       "      <td>গত ২৭ ফেব্রুয়ারি ২০১৯, প্রথম আলোর আয়োজনে এবং...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>29790</td>\n",
       "      <td>আম্পানে খেত-ঘের শেষ, নিঃস্ব বহু ...</td>\n",
       "      <td>২২ মে, ২০২০</td>\n",
       "      <td>আম্পানে খেত-ঘের শেষ, নিঃস্ব বহু মানুষ</td>\n",
       "      <td>‘ঘরের পোতাডাও (ভিটা) পানিতে ধুইয়া লইয়া গ্যাছে।...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>15070</td>\n",
       "      <td>ব্যাপক বন্যা | প্রথম আলো - Prothom Alo</td>\n",
       "      <td>৩১ ডিসেম্বর, ২০১৭</td>\n",
       "      <td>ব্যাপক বন্যা</td>\n",
       "      <td>পুরোদমে বর্ষা শুরুর আগেই গেল বছর দেশের হাওরাঞ্...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>10272</td>\n",
       "      <td>পঞ্চগড়ে নিম্নাঞ্চল প্লাবিত ...</td>\n",
       "      <td>১৩ জুলাই, ২০২০</td>\n",
       "      <td>পঞ্চগড়ে নিম্নাঞ্চল প্লাবিত, সাঁকো বিলীন</td>\n",
       "      <td>টানা তিন দিনের ভারী বৃষ্টি আর উজান থেকে নেমে আ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>10997</td>\n",
       "      <td>Amphan Cyclone: Mamata Banerjee monitoring fro...</td>\n",
       "      <td>২০ মে, ২০২০</td>\n",
       "      <td>দাপট বাড়াচ্ছে আমফান, নবান্নের কন্ট্রোল রুমে ব...</td>\n",
       "      <td>তরুণকান্তি দাস: দিঘা থেকে বেরিয়ে গিয়েছে ঝড়।...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1146 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                              title  \\\n",
       "0      8639                       কুষ্টিয়ায় পানিবন্দী ৩৫ ...   \n",
       "1     27195                          পানিবন্দি কয়েক লাখ মানুষ   \n",
       "2       292          মৌলভীবাজারে পাহাড়ি ঢলে ... - Prothom Alo   \n",
       "3     28981                  দুর্যোগ সহনশীল নগর গঠনে নারীর ...   \n",
       "4      4913               গরমের তেজে নিস্তেজ জীবন | 942173 ...   \n",
       "...     ...                                                ...   \n",
       "1141   7198                  দুর্যোগ মোকাবিলায় হাসপাতালের ...   \n",
       "1142  29790                আম্পানে খেত-ঘের শেষ, নিঃস্ব বহু ...   \n",
       "1143  15070             ব্যাপক বন্যা | প্রথম আলো - Prothom Alo   \n",
       "1144  10272                    পঞ্চগড়ে নিম্নাঞ্চল প্লাবিত ...   \n",
       "1145  10997  Amphan Cyclone: Mamata Banerjee monitoring fro...   \n",
       "\n",
       "                   date                                           headline  \\\n",
       "0             ৩ দিন আগে               কুষ্টিয়ায় পানিবন্দী ৩৫ গ্রামের মানুষ   \n",
       "1        ১৩ জুলাই, ২০২০                           পানিবন্দি কয়েক লাখ মানুষ   \n",
       "2           ৫ জুন, ২০১৭    মৌলভীবাজারে পাহাড়ি ঢলে লক্ষাধিক মানুষ পানিবন্দী   \n",
       "3          ২৫ ফেব, ২০১৮              দুর্যোগ সহনশীল নগর গঠনে নারীর ভূমিকা   \n",
       "4         ৫ আগস্ট, ২০২০                            গরমের তেজে নিস্তেজ জীবন   \n",
       "...                 ...                                                ...   \n",
       "1141     ২৬ মার্চ, ২০১৯             দুর্যোগ মোকাবিলায় হাসপাতালের প্রস্তুতি   \n",
       "1142        ২২ মে, ২০২০              আম্পানে খেত-ঘের শেষ, নিঃস্ব বহু মানুষ   \n",
       "1143  ৩১ ডিসেম্বর, ২০১৭                                       ব্যাপক বন্যা   \n",
       "1144     ১৩ জুলাই, ২০২০            পঞ্চগড়ে নিম্নাঞ্চল প্লাবিত, সাঁকো বিলীন   \n",
       "1145        ২০ মে, ২০২০  দাপট বাড়াচ্ছে আমফান, নবান্নের কন্ট্রোল রুমে ব...   \n",
       "\n",
       "                                                content  is_flood  \n",
       "0     চরাঞ্চলে সাধারণত আষাঢ়–ভাদ্র মাসের মাঝামাঝি পর্...     False  \n",
       "1     সুনামগঞ্জ প্রতিনিধি\\nশেষের পাতা  ১৩ জুলাই ২০২০...      True  \n",
       "2     >\\nজনপ্রতিনিধিরা ব্যক্তিগত উদ্যোগে কিছু ত্রাণ ...      True  \n",
       "3     ১৮ ফেব্রুয়ারি ২০১৮, ডেইলি স্টার ওকেয়ার বাংলাদে...     False  \n",
       "4     কখনো ঠা ঠা রোদ আবার কখনো মধ্য শ্রাবণের অঝোরধার...     False  \n",
       "...                                                 ...       ...  \n",
       "1141  গত ২৭ ফেব্রুয়ারি ২০১৯, প্রথম আলোর আয়োজনে এবং...     False  \n",
       "1142  ‘ঘরের পোতাডাও (ভিটা) পানিতে ধুইয়া লইয়া গ্যাছে।...      True  \n",
       "1143  পুরোদমে বর্ষা শুরুর আগেই গেল বছর দেশের হাওরাঞ্...      True  \n",
       "1144  টানা তিন দিনের ভারী বৃষ্টি আর উজান থেকে নেমে আ...      True  \n",
       "1145  তরুণকান্তি দাস: দিঘা থেকে বেরিয়ে গিয়েছে ঝড়।...      True  \n",
       "\n",
       "[1146 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df1, df2])\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "careful-irish",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "কুষ্টিয়ায় পানিবন্দী ৩৫ ...\n",
      "কুষ্টিয়ায় পানিবন্দী ৩৫ গ্রামের মানুষ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['title'].iloc[0]), print(df['headline'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-volunteer",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Standardized Fivefold with Headline, with labelled data english translations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-negative",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Five-Fold Stratified Sampling With Translations\n",
    "\n",
    "Main File Used for Majority of Testing:\n",
    "- fiveFoldStratifiedSamplingWithTranslation.csv\n",
    "\n",
    "For text after standardization (basic typing standardized):\n",
    "- standardizedWordFiveFoldStratifiedSampling.csv\n",
    "\n",
    "For text after more substantial preprocessing (removing stopwords and such) [not great for classification]:\n",
    "- preprocessedWordFiveFoldStratifiedSampling.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "incomplete-disclosure",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'translation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-4f530595a64d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBengaliStandardizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'translation'"
     ]
    }
   ],
   "source": [
    "from bengali_tools.bengali_preprocessing import BengaliStandardizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "import translation\n",
    "\n",
    "bs = BengaliStandardizer()\n",
    "X, y = df['content'].apply(bs.standandize), df['is_flood']\n",
    "skf = StratifiedKFold(shuffle=True, random_state=42)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "#splits_df['translated'] = df['content'].apply(lambda t: translate_bulk(t, target_lang = 'en', source_lang='bn'))\n",
    "\n",
    "splits_df = pd.concat([X, y], axis=1) #d%colors'content', 'is_flood']].copy()\n",
    "for i, indices in enumerate(skf.split(X, y)):\n",
    "    test_inds = set(indices[1])\n",
    "    splits_df[f\"split_{i}\"] = [\"train\" if i in test_inds else \"test\" for i in range(len(df))]\n",
    "    \n",
    "splits_df\n",
    "#splits_df.to_csv(\"preprocessedFiveFoldStratifiedSampling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "soviet-attraction",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "splits_df.to_csv(\"standardizedWordFiveFoldStratifiedSampling.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-momentum",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train-Valid-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "french-equality",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643 training examples\n",
      "161 validation examples\n",
      "202 test examples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size = 0.20, random_state = 42)\n",
    "\n",
    "print(f\"{len(X_train)} training examples\\n{len(X_valid)} validation examples\\n{len(X_test)} test examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-charge",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_dt=pd.DataFrame([X_train, y_train]).T\n",
    "valid_dt=pd.DataFrame([X_valid, y_valid]).T\n",
    "test_dt=pd.DataFrame([X_test, y_test]).T\n",
    "train_dt['type'] = 'train'\n",
    "valid_dt['type'] = 'valid'\n",
    "test_dt['type'] = 'test'\n",
    "splits_df = pd.concat([train_dt, valid_dt, test_dt])\n",
    "\n",
    "#splits_df.to_csv(\"training_splits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-reader",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "splits_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-azerbaijan",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Old Code for combing all English Data From Tagtog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "excess-easter",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, '..')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "directed-drive",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "LABELED_PATH = \"../bengali_data_management/labelled_samples/\"\n",
    "dfs = []\n",
    "for sample in ['dailystar.csv', 'dhaka_tribune.csv', \n",
    "               \"is_flood_new.csv\", \"is_flood3.csv\",\n",
    "               \"is_flood.csv\", \"eng_articles.csv\"\n",
    "              ]:\n",
    "    dfs.append(pd.read_csv(os.path.join(LABELED_PATH, sample), index_col=0))\n",
    "\n",
    "df_raw = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bigger-deficit",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def preprocess_eng(txt):\n",
    "    text = \" \".join(seg for seg in txt.split(\"\\n\") if len(seg) > 0 and \"Date Published:\" not in seg)\n",
    "    #if len(text) < 100:\n",
    "    #    return None\n",
    "    return text\n",
    "\n",
    "df = pd.concat([df_raw['content'].apply(preprocess_eng), df_raw['is_flood']], axis = 1,)\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "promotional-candy",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1025 training examples\n",
      "114 test examples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df['content'], df['is_flood']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = 42)\n",
    "\n",
    "print(f\"{len(X_train)} training examples\\n{len(X_test)} test examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "assured-environment",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dt=pd.DataFrame([X_train, y_train]).T\n",
    "test_dt=pd.DataFrame([X_test, y_test]).T\n",
    "train_dt['type'] = 'train'\n",
    "test_dt['type'] = 'test'\n",
    "splits_df = pd.concat([train_dt, test_dt])\n",
    "\n",
    "splits_df.to_csv(\"english_training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "associate-character",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>is_flood</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>Flood situation worsens in JagannathpurOverflo...</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Further east, Iran has the third highest case ...</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>tuesday, 21 july, 2020 people in the flood-aff...</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>Hundreds of houses have been swept away as wat...</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>These jute mills are located in Khulna's Khali...</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>The community health workers are unsung heroes...</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>April 24, 1972  IMPORT POLICY ANNOUNCED The co...</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>tuesday, 21 july, 2020 under the influence of ...</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Police pressed charges against eight people ov...</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>India's national carrier Air India will operat...</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content is_flood  type\n",
       "668  Flood situation worsens in JagannathpurOverflo...     True  test\n",
       "324  Further east, Iran has the third highest case ...    False  test\n",
       "624  tuesday, 21 july, 2020 people in the flood-aff...     True  test\n",
       "690  Hundreds of houses have been swept away as wat...     True  test\n",
       "473  These jute mills are located in Khulna's Khali...    False  test\n",
       "..                                                 ...      ...   ...\n",
       "512  The community health workers are unsung heroes...    False  test\n",
       "109  April 24, 1972  IMPORT POLICY ANNOUNCED The co...    False  test\n",
       "587  tuesday, 21 july, 2020 under the influence of ...     True  test\n",
       "362  Police pressed charges against eight people ov...    False  test\n",
       "734  India's national carrier Air India will operat...     True  test\n",
       "\n",
       "[77 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-messaging",
   "metadata": {},
   "source": [
    "# English Training Data\n",
    "\n",
    "Collect files used for training on english articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-conference",
   "metadata": {},
   "source": [
    "## Tejits Original English Training Data with His Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-discipline",
   "metadata": {},
   "source": [
    "### Load it from processed version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sized-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd\n",
    "dt = pd.read_csv(os.path.join('', 'training_datasets', 'original_english_training_dataset.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "conventional-hours",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small portion groyen rajshahi city sreerampur ...</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>students bring forth various allegations rulin...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>says sorry lacking role protest continue amid ...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>major incidents declared emergency services so...</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>problem stomach acid moves tube called oesopha...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>none brahmaputra erode area ulipurulipur kurig...</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>tuesday july flood situation faridpur kurigram...</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>none least villages akhaura upazila brahmanbar...</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>earthquake measuring magnitude richter scale l...</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>meter area rajbari city flood embankment damag...</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1597 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label  split\n",
       "0    small portion groyen rajshahi city sreerampur ...   True  train\n",
       "1    students bring forth various allegations rulin...  False  train\n",
       "2    says sorry lacking role protest continue amid ...  False  train\n",
       "3    major incidents declared emergency services so...   True  train\n",
       "4    problem stomach acid moves tube called oesopha...  False  train\n",
       "..                                                 ...    ...    ...\n",
       "315  none brahmaputra erode area ulipurulipur kurig...   True   test\n",
       "316  tuesday july flood situation faridpur kurigram...   True   test\n",
       "317  none least villages akhaura upazila brahmanbar...   True   test\n",
       "318  earthquake measuring magnitude richter scale l...  False   test\n",
       "319  meter area rajbari city flood embankment damag...   True   test\n",
       "\n",
       "[1597 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-stream",
   "metadata": {},
   "source": [
    "### Create it from original raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "severe-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pandas as pd\n",
    "\n",
    "with open(\"EnglishDataset/original_train_test_split_english_raw.json\", \"r\") as f:\n",
    "    dt = json.load(f)\n",
    "\n",
    "set(dt['train'][0].keys())\n",
    "english_dfs = [\n",
    "    pd.DataFrame([{'text': item['text'], 'label': item['is_flood'], 'split': _type} for item in dt[_type]])\n",
    "    for _type in ('train', 'test')\n",
    "]\n",
    "english_df = pd.concat(english_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "refined-johnson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small portion groyen rajshahi city sreerampur ...</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>students bring forth various allegations rulin...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>says sorry lacking role protest continue amid ...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>major incidents declared emergency services so...</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>problem stomach acid moves tube called oesopha...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>none brahmaputra erode area ulipurulipur kurig...</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>tuesday july flood situation faridpur kurigram...</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>none least villages akhaura upazila brahmanbar...</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>earthquake measuring magnitude richter scale l...</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>meter area rajbari city flood embankment damag...</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1597 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label  split\n",
       "0    small portion groyen rajshahi city sreerampur ...   True  train\n",
       "1    students bring forth various allegations rulin...  False  train\n",
       "2    says sorry lacking role protest continue amid ...  False  train\n",
       "3    major incidents declared emergency services so...   True  train\n",
       "4    problem stomach acid moves tube called oesopha...  False  train\n",
       "..                                                 ...    ...    ...\n",
       "315  none brahmaputra erode area ulipurulipur kurig...   True   test\n",
       "316  tuesday july flood situation faridpur kurigram...   True   test\n",
       "317  none least villages akhaura upazila brahmanbar...   True   test\n",
       "318  earthquake measuring magnitude richter scale l...  False   test\n",
       "319  meter area rajbari city flood embankment damag...   True   test\n",
       "\n",
       "[1597 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-preserve",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Alternate Split of English Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "handmade-locator",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json, pandas as pd\n",
    "\n",
    "with open(\"english_data.json\", \"r\") as f:\n",
    "    dt = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "approximate-special",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json, pandas as pd\n",
    "\n",
    "#with open(\"EnglishDataset/original_train_test_split_english_raw.json\", \"r\") as f:\n",
    "#    dt = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "peripheral-chancellor",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "set(dt['train'][0].keys())\n",
    "english_dfs = [\n",
    "    pd.DataFrame([{'text': item['text'], 'label': item['is_flood'], 'split': _type} for item in dt[_type]])\n",
    "    for _type in ('train', 'test')\n",
    "]\n",
    "english_df = pd.concat(english_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "departmental-sequence",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "english_df.to_csv('training_datasets/original_english_training_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "relative-pointer",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f3c9ca16f851>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'training_datasets'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'original_english_training_dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dt = pd.read_csv(os.path.join('', 'training_datasets', 'original_english_training_dataset.csv'), index_col=0)\n",
    "dt[split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "narrative-failing",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "date_published = re.compile(\"Date Published:\\d+-\\d+-\\d+ \\d+:\\d+:\\d+(\\+00:00)?\")\n",
    "news_summary = re.compile(\"NEWS SUMMARY(:?)[^\\na-z]*\\n\")\n",
    "\n",
    "def remove_date(text):\n",
    "    #text = text.replace(\"tuesday, 21 july, 2020\", \"\")\n",
    "    text = news_summary.sub(\"\", text)\n",
    "    return date_published.sub(\"\", text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "standard-passenger",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_raw = pd.DataFrame(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ruled-maine",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_raw['text'].apply(remove_date), df_raw['is_flood']], axis = 1,)\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "forbidden-atlas",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242 training examples\n",
      "138 test examples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df['text'], df['is_flood']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = 42)\n",
    "\n",
    "print(f\"{len(X_train)} training examples\\n{len(X_test)} test examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cognitive-logan",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dt=pd.DataFrame([X_train, y_train]).T\n",
    "test_dt=pd.DataFrame([X_test, y_test]).T\n",
    "train_dt['type'] = 'train'\n",
    "test_dt['type'] = 'test'\n",
    "splits_df = pd.concat([train_dt, test_dt])\n",
    "\n",
    "splits_df.to_csv(\"english_training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "least-salon",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_flood</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>Water in the Teesta River is flowing above the...</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>The ambassador extended his sincere felicitati...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>Bangladesh Getting U.S. Aid\\n1987-09-26T05:00:...</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Around 500km coastal embankments of Khulna, Ba...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>Railways Minister Nurul Islam Sujan today in p...</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>Floodwaters rushing down from highlands in Ind...</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Date Published:None Two days have been passed ...</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>The deal has been signed by US special envoy Z...</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>3 Die as Police Clash With Protesters in Bangl...</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>Parts of low-lying areas close to river banks ...</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1380 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text is_flood   type\n",
       "503   Water in the Teesta River is flowing above the...     True  train\n",
       "817   The ambassador extended his sincere felicitati...    False  train\n",
       "1078  Bangladesh Getting U.S. Aid\\n1987-09-26T05:00:...     True  train\n",
       "231   Around 500km coastal embankments of Khulna, Ba...    False  train\n",
       "743   Railways Minister Nurul Islam Sujan today in p...    False  train\n",
       "...                                                 ...      ...    ...\n",
       "636   Floodwaters rushing down from highlands in Ind...     True   test\n",
       "493   Date Published:None Two days have been passed ...     True   test\n",
       "1354  The deal has been signed by US special envoy Z...    False   test\n",
       "752   3 Die as Police Clash With Protesters in Bangl...    False   test\n",
       "435   Parts of low-lying areas close to river banks ...     True   test\n",
       "\n",
       "[1380 rows x 3 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-vocabulary",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Full English Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "underlying-california",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def parse_paper_content_from_eng_json(content, paper = None):\n",
    "    parsed = []\n",
    "    for row in content:\n",
    "        parsed_row = {\n",
    "            \"content\": row['article']['text'],\n",
    "            \"headline\": row['article']['headline'],\n",
    "            \"date\": row['meta']['datePublished'] if row['meta']['datePublished'] is not None else row['meta']['dateModified'],\n",
    "            \"link\": \"https://bdnews24.com/bangladesh/2014/11/01/massive-blackout-brings-bangladesh-to-its-knees\",\n",
    "            \"paper\": paper,\n",
    "        }\n",
    "        parsed.append(parsed_row)\n",
    "        \n",
    "    return pd.DataFrame(parsed)\n",
    "\n",
    "with open(bdnews1_data.json\", 'r') as f:\n",
    "    data = json.load(f)\n",
    "    pared_df = parse_paper_content_from_eng_json(data, paper= 'bdnews1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "swiss-effort",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "paper_dir = \"EnglishDataset/all_paper_data\"\n",
    "\n",
    "all_parsed_dfs = []\n",
    "for file in os.listdir(paper_dir):\n",
    "    if file.split('.')[-1] != 'json':\n",
    "        continue\n",
    "    paper = file.split('_')[0]\n",
    "    with open(os.path.join(paper_dir, file), 'r') as f:\n",
    "        data = json.load(f)\n",
    "        pared_df = parse_paper_content_from_eng_json(data, paper=paper)\n",
    "        all_parsed_dfs.append(pared_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "backed-accused",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "english_df = pd.concat(all_parsed_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "empirical-sodium",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "english_df.to_csv(\"predictions/fullEnglishDataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-saying",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Cross-Lingual Dataset Preparation with Unlabeled Data\n",
    "\n",
    "Must generate fiveFoldStratifiedSamplesFirst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "structured-backup",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from bengali_tools.bengali_preprocessing import BengaliStandardizer\n",
    "import pandas as pd\n",
    "\n",
    "bs = BengaliStandardizer()\n",
    "unlabelled_data = pd.read_csv(\"../bengali_data_management/samples/unformated/9_25_2021_unlabelled_sample_1.csv\", index_col=0)\n",
    "unlabelled_data[\"is_flood\"] = -1\n",
    "\n",
    "X_u, y_u = load_X(unlabelled_data), load_y(unlabelled_data)\n",
    "df_u = pd.concat([X_u, y_u], axis=1).rename(columns={0:'text', 'is_flood':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "institutional-indie",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split_0</th>\n",
       "      <th>split_1</th>\n",
       "      <th>split_2</th>\n",
       "      <th>split_3</th>\n",
       "      <th>split_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>কুষ্টিয়ায় পানিবন্দী ৩৫ গ্ব়ামেব় মানুষ \\nচব়...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>পানিবন্দি কয়েক লাখ মানুষ \\nসুনামগঞ্জ প্ব়তিনি...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>মৌলভীবাজাব়ে পাহাড়ি ঢলে লক্ষাধিক মানুষ পানিবন...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>দুব়্যোগ সহনশীল নগব় গঠনে নাব়ীব় ভূমিকা \\n১৮...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>গব়মেব় তেজে নিস্তেজ জীবন \\nকখনো ঠা ঠা ব়োদ আব...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>দুব়্যোগ মোকাবিলায় হাসপাতালেব় প্ব়স্তুতি \\nগ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>আম্পানে খেত-ঘেব় শেষ, নিঃস্ব বহু মানুষ \\n‘ঘব়ে...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>ব্যাপক বন্যা \\nপুব়োদমে বব়্ষা শুব়ুব় আগেই গে...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>পঞ্চগড়ে নিম্নাঞ্চল প্লাবিত, সাঁকো বিলীন \\nটান...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>দাপট বাড়াচ্ছে আমফান, নবান্নেব় কন্ট্ব়োল ব়ুম...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>train</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1146 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label split_0  \\\n",
       "0     কুষ্টিয়ায় পানিবন্দী ৩৫ গ্ব়ামেব় মানুষ \\nচব়...      0   train   \n",
       "1     পানিবন্দি কয়েক লাখ মানুষ \\nসুনামগঞ্জ প্ব়তিনি...      1    test   \n",
       "2     মৌলভীবাজাব়ে পাহাড়ি ঢলে লক্ষাধিক মানুষ পানিবন...      1    test   \n",
       "3     দুব়্যোগ সহনশীল নগব় গঠনে নাব়ীব় ভূমিকা \\n১৮...      0    test   \n",
       "4     গব়মেব় তেজে নিস্তেজ জীবন \\nকখনো ঠা ঠা ব়োদ আব...      0   train   \n",
       "...                                                 ...    ...     ...   \n",
       "1141  দুব়্যোগ মোকাবিলায় হাসপাতালেব় প্ব়স্তুতি \\nগ...      0   train   \n",
       "1142  আম্পানে খেত-ঘেব় শেষ, নিঃস্ব বহু মানুষ \\n‘ঘব়ে...      1    test   \n",
       "1143  ব্যাপক বন্যা \\nপুব়োদমে বব়্ষা শুব়ুব় আগেই গে...      1    test   \n",
       "1144  পঞ্চগড়ে নিম্নাঞ্চল প্লাবিত, সাঁকো বিলীন \\nটান...      1    test   \n",
       "1145  দাপট বাড়াচ্ছে আমফান, নবান্নেব় কন্ট্ব়োল ব়ুম...      1    test   \n",
       "\n",
       "     split_1 split_2 split_3 split_4  \n",
       "0       test    test    test    test  \n",
       "1      train    test    test    test  \n",
       "2       test    test    test   train  \n",
       "3       test   train    test    test  \n",
       "4       test    test    test    test  \n",
       "...      ...     ...     ...     ...  \n",
       "1141    test    test    test    test  \n",
       "1142    test    test    test   train  \n",
       "1143   train    test    test    test  \n",
       "1144    test    test    test   train  \n",
       "1145    test   train    test    test  \n",
       "\n",
       "[1146 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bengali_tools.bengali_preprocessing import BengaliStandardizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "\n",
    "def load_X(df):\n",
    "    return df.apply(lambda row: bs.standandize(\"{headline} \\n{content}\".format(**row)), axis = 1)\n",
    "\n",
    "def load_y(df):\n",
    "    return df[\"is_flood\"].apply(int)\n",
    "\n",
    "bs = BengaliStandardizer()\n",
    "X, y = load_X(df), load_y(df)\n",
    "skf = StratifiedKFold(shuffle=True, random_state=42)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "splits_df = pd.concat([X, y], axis=1).rename(columns={0:'text', 'is_flood':'label'}) #d%colors'content', 'is_flood']].copy()\n",
    "for i, indices in enumerate(skf.split(X, y)):\n",
    "    test_inds = set(indices[1])\n",
    "    splits_df[f\"split_{i}\"] = [\"train\" if i in test_inds else \"test\" for i in range(len(df))]\n",
    "    \n",
    "splits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "biblical-capacity",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "standardize_df_with_unlabelled = pd.concat([df_u, splits_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fuzzy-mouse",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "standardize_df_with_unlabelled.to_csv(\"standardizedFiveFoldWithUnlabelled.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-posting",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Testing Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "controlled-eligibility",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datasets = pd.read_csv(\"classification_datasets.csv\", index_col=\"index\")\n",
    "_, path, identifier, _ = next(entry for i, entry in datasets.iterrows() if entry.dataset_name == \"rawFivefoldWithTranslation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "abroad-spelling",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import os\n",
    "\n",
    "def load_dataset(index: Optional[int] = None, name: Optional[str] = None, _id: Optional[str] = None, filepath: Optional[str] = None, ROOT=''):\n",
    "    datasets = pd.read_csv(\"classification_datasets.csv\", index_col=\"index\")\n",
    "    if index is not None:\n",
    "        row = datasets.iloc[index]\n",
    "    elif name is not None:\n",
    "        try:\n",
    "            row = next(entry for i, entry in datasets.iterrows() if entry.dataset_name == name)\n",
    "        except StopIteration:\n",
    "            raise KeyError(f\"Could not find dataset for name: {name}\")\n",
    "    elif _id is not None:\n",
    "        try:\n",
    "            row = next(entry for i, entry in datasets.iterrows() if entry.identifier == _id)\n",
    "        except StopIteration:\n",
    "            raise KeyError(f\"Could not find dataset for id: {_id}\")\n",
    "    elif filepath is not None:\n",
    "        path = filepath\n",
    "        identifier = None\n",
    "        return pd.read_csv(os.path.join(ROOT, path)), identifier\n",
    "    else:\n",
    "        raise ValueError(\"Did not specify dataset to load\")\n",
    "\n",
    "    name, path, identifier, desc = row\n",
    "    print(f\"Loaded {name} dataset\")\n",
    "    return pd.read_csv(os.path.join(ROOT, path), index_col=0), identifier\n",
    "\n",
    "def getFivefoldStandard(USE_TRANSLATED = False):\n",
    "    df, identifier = load_dataset(_id = \"rfft\")\n",
    "    X_trains, X_tests, y_trains, y_tests = [[df[col][df[f\"split_{i}\"] == cat] for i in range(5)]\n",
    "            for col in ('content' if not USE_TRANSLATED else 'translated', 'is_flood') \n",
    "            for cat in ('test', 'train')\n",
    "           ]\n",
    "    print(f\"{len(y_trains)} folds\\n{len(y_trains[0])} training examples\\n{len(y_tests[0])} test examples\")\n",
    "    return df, identifier, X_trains, X_tests, y_trains, y_tests\n",
    "\n",
    "def getFivefoldWithUnlabelled():\n",
    "    df, identifier = load_dataset(_id = \"sffu\")\n",
    "    df_u = df[df['label']==-1]\n",
    "    df_l = df[df['label']!=-1]\n",
    "    X_u = df_u\n",
    "    X_tests, X_trains, y_tests, y_trains = [[df_l[col][df_l[f\"split_{i}\"] == cat] for i in range(5)]\n",
    "            for col in ('text', 'label') \n",
    "            for cat in ('test', 'train')\n",
    "           ]\n",
    "    print(f\"{len(y_trains)} folds\\n{len(X_u)} unlabelled examples\\n{len(y_trains[0])} labelled training examples\\n{len(y_tests[0])} labelled test examples\")\n",
    "    return df, identifier, X_trains, X_tests, y_trains, y_tests, X_u\n",
    "\n",
    "def getEnglishDataset():\n",
    "    eng_df, identifier = load_dataset(_id = \"rtte\")\n",
    "    eng_train_dt = eng_df[eng_df['type'] == 'train']\n",
    "    eng_test_dt = eng_df[eng_df['type'] == 'test']\n",
    "    eng_X_train, eng_y_train = eng_train_dt['text'], eng_train_dt['is_flood']\n",
    "    eng_X_test, eng_y_test = eng_test_dt['text'], eng_test_dt['is_flood']\n",
    "    print(f\"English Examples\\n{len(eng_X_train)} training examples\\n{len(eng_X_test)} test examples\")\n",
    "    return eng_df, identifier, eng_X_train, eng_X_test, eng_y_train, eng_y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "revised-logistics",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded fivefoldWithUnlabelled dataset\n",
      "5 folds\n",
      "7184 unlabelled examples\n",
      "230 training examples\n",
      "916 test examples\n"
     ]
    }
   ],
   "source": [
    "df, ds_id, X_trains, X_tests, y_trains, y_tests, X_u =  getFivefoldWithUnlabelled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-guess",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
